---
title: "Introduction to Open Data Science - Final assignment"
author: Emanuela Giovanna Calabi
date: 06.03.2017
output:
  html_document:
    code_folding: hide
---

emanuela.calabi@helsinki.fi

## Abstract

The following analysis was made by a Computer Science undergraduate as final assignment for the MOOC "Introduction to Open Data Science". The "Human development index" dataset was used for this analysis. The analysis is concerned with the mean years of education in countries of the world and aims to find which factors are associated with a high or low mean. Statistical tools have been uses to read, manipulate and plot data, in particular pairplots, correlation plots, linear regression, linear discriminant analysis and k-means using the R programming language.

## Introduction

The object of this analysis is the Human Development Index. The "human" dataset contains various indicators for each country, which quantify socio-economical wealth and gender equality of such country. More info on the data can be found here: http://hdr.undp.org/en/content/human-development-index-hdi.

The following analysis concerns the the mean years of education (edu.mean) and its relations to the other variables in the set. I expect that countries with a higher edu.mean have a high Gross National Income per capita, longer life expectancy at birth and longer expectancy of education. On the contrary, I suppose that a lower edu.mean corresponds to a higher Gender Inequality Index and a higher adolescent birthrate.

## Data wrangling

The "human" dataset has been created by joining two datasets ("human_development" and "gender_inequality"). Variables have been renamed to shorter and more intuitive names for practical reasons. The last 7 observations concerning regions of the world have been removed to focus on countries only. In the end 8 variables were selected to keep for the analysis. Such manipulations of the dataset can be found in my data wrangling exercise at this link: https://github.com/egcmi/IODS-final/blob/master/create_human.R

## Data analysis

Let us start by reading and exploring the data.
```{r}
human <- read.csv("~/Desktop/IODS/IODS-final/human.txt", header=TRUE, row.names=1)
dim(human)
```

There are 155 observations of 8 variables, i.e. 155 countries are taken into consideration. The variable names and their meanings are:

 * **edu2.fm**: Ratio between females and males with secondary education
 * **life.exp**: Life expectancy at birth
 * **edu.exp**: Expected years of education
 * **edu.mean**: Mean years of education
 * **GNI**: Gross National Income per capita
 * **GII**: Gender Inequality Index
 * **mat.mor**: Maternal mortality ratio
 * **ado.birth**: Adolescent birthrate

```{r}
str(human)
summary(human)
```

Let us visualise the data using ggpairs. None of the variables show normal distribution. In particular GNI, mat.mor and ado.birth are very left skewed, while edu2.fm, lab.fm, life.exp and edu.mean are slightly right skewed. Edu.exp has exponential distribution while GII is multimodal.
```{r}
library(GGally)
ggpairs(human)
```


Let us plot the correlation between the variables in the dataset. We can see that edu2.fm is positively correlated to life.exp, edu.exp, edu.mean and GNI and all these variables are strongly positively correlated to each other. Notice how the graph appears split by a big, red rectangle indicating strong negative correlation. The variables concerned in such rectangle are GII, mat.mor and ado.birth which negatively correlate to all other variables. Unsurprisingly GII, mat.mor and ado.birth are strongly positively correlated, meaning that maternal mortality and adolescent birthrate are higher in such countries where gender inequality is stronger.
```{r}
library(magrittr)
library(corrplot)
cor(human) %>% corrplot(method="circle", type="upper", cl.pos="b", tl.pos="d", tl.cex=0.6)

```

### Linear regression

Let us perform linear regression on the human data. In this model we consider edu.mean as a target variable, whose explanatory variables are edu.exp, life.exp and edu2.fm. As we can see in the coefficients the standard error for edu.exp, life.exo and edu2.fm is between 0 and 1 and the P value is very low so we can conclude that there is a statistical relation between the explanatory variables and the target variable.
```{r}
lm(edu.mean ~ edu.exp + life.exp + edu2.fm, data=human) %>% summary
```

### Linear discriminant analysis

Now let us perform Linear Discriminant Analysis in order to make predictions about the target variable edu.mean. The explanatory variables are edu.exp, life.exp and edu2.fm. As we can see in the Proportion of trace, Linear Discriminant 1 (LD1) describes 71.7% of the variance in the group. According to the coefficients of linear discriminants the explanatory variables are all relevant to edu.mean, being edu2.fm the most influent. 

```{r}
library(MASS)
lda_human <- lda(edu.mean ~ edu.exp + life.exp + edu2.fm, data=human)
lda_human
```

Our next step is visualising the LDA by means of LDA biplot arrows. In the scatterplot we can see from the length of the arrows, edu2.fm is the variable which has the largest impact on edu.mean. Edu.exp and life.exp have minor influence.
```{r}
lda.arrows <- function(x, myscale = 1, arrow_heads = 0.1, color = "red", tex = 0.75, choices = c(1,2)){
  heads <- coef(x)
  arrows(x0 = 0, y0 = 0, 
         x1 = myscale * heads[,choices[1]], 
         y1 = myscale * heads[,choices[2]], col=color, length = arrow_heads)
  text(myscale * heads[,choices], labels = row.names(heads), 
       cex = tex, col=color, pos=3)
}

plot(lda_human, col=human$edu.mean, pch=human$edu.mean, dimen=2)
lda.arrows(lda_human, myscale = 1)
```

### K-means

The final step of our analysis is K-means. The first step for K-means is finding the number of clusters that are needed. For this reason we compute the *total within cluster sum of squares* (TWCSS) first. We can see in the plot that the TWCSS drops significantly at 2. This means that 2 is the optimal number of clusters.
```{r}
dist_human <- dist(human)
twcss <- sapply(1:10, function(k){kmeans(dist_human, k)$tot.withinss})
plot(1:10, twcss, type='b')
```

After finding out the number of clusters needed, we can proceed and compute K-means. We used the euclidean method to determine the distance between observation. The variable GNI is the one where the difference is most clear compared to the pairplot without clusters.
```{r}
set.seed(123)
km_human <- kmeans(dist_human, centers=2)
pairs(human, col=km_human$cluster)
```

## Conclusion

After the data analisis, it emerges that edu.mean is positively correlated to life.exp, edu.exp, edu2.fm and GNI. Edu.mean can also be explained by taking into consideration edu.exp, life.exp and edu2.fm as explanatory variables. Moreover edu2.fm is the most influent explanatory variable. On the other hand countries with a lower edu.mean experience higher values in GII and ado.birth.